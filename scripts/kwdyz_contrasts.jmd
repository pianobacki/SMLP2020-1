---
Title: Contrast Coding of Visual Attention Effects
Author: Reinhold Kliegl
Date: 2020-09-10
---

```julia
using DrWatson
@quickactivate "SMLP2020"

using RCall 
using DataFrames, DataFramesMeta
using MixedModels
using Statistics: mean, std
using StatsModels: pretty_mat, ContrastsCoding


#using StatsModels
#using LinearAlgebra, Statistics
```

## Example data

We take the `KWDYZ` dataset (Kliegl et al., 2011; Frontiers). This is an experiment looking at three effects of visual cueing under four different cue-target relations (CTRs). Two horizontal rectangles are displayed above and below a central fixation point or they displayed in vertical orientation to the left and right of the fixation point.  Subjects react to the onset of a small visual target occuring at one of the four ends of the two rectangles. The target is cued validly on 70% of trials by a brief flash of the corner of the rectangle at which it appears; it is cued invalidly at the three other locations 10% of the trials each. 

We specify three contrasts for the four-level factor CTR that are derived from spatial, object-based, and attractor-like features of attention. They map onto sequential differences between appropriately ordered factor levels. Interestingly, a different theoretical perspective, derived from feature overlap, leads to a different set of contrasts. Can the results refute one of the theoretical perspectives?

We also have a dataset from a replication and extension of this study (Kliegl, Kuschela, & Laubrock, 2015). Both data sets are available in [R-package RePsychLing](https://github.com/dmbates/RePsychLing/tree/master/data/) (Baayen et al., 2014).

```julia

# RCall
R"load($datadir('KWDYZ.rda'))";
dat1 = @rget KWDYZ;
dat1 = select(dat1, :subj => :Subj, :tar => :CTR, :rt);

# Set the factor levels
dat1 = @linq dat1 |>
        transform(CTR = levels!(categorical(:CTR), ["val", "sod", "dos", "dod"]));

first(dat1, 5)
describe(dat1)

# Descriptive statistics
cellmeans = by(dat1, [:CTR], 
            meanRT = :rt => mean, sdRT = :rt => std, n = :rt => length,
            semean = :rt => x -> std(x)/sqrt(length(x)))

OM = mean(dat1.rt)             # mean of observations
GM = mean(cellmeans.meanRT)    # grand mean = mean of conditions
```

## SeqDiffCoding 

This contrast corresponds to `MASS::contr.sdif()` in R.

```julia
cntr1 = Dict(
    :CTR  => SeqDiffCoding(levels=["val", "sod", "dos", "dod"]),
    :Subj => Grouping()
);


formula = @formula  rt ~ 1 + CTR + (1 + CTR | Subj)
m1 = fit(MixedModel, formula, dat1, contrasts=cntr1)

# Here is the general solution - manual hypothesis coding 
cntr1b = Dict(
    :CTR => HypothesisCoding([-1  1  0  0
                               0 -1  1  0
                               0  0 -1  1],
            levels=["val", "sod",  "dos", "dod"])
);

m1b = fit(MixedModel, formula, dat1, contrasts=cntr1b)

```

Controlling the ordering of levels for contrasts:

1.  kwarg `levels=` to order the levels; the first is set as the baseline.
2.  kwarg `base=` to fix the baseline level.

The assignment of random factors such as `Subj` to `Grouping()` is only necessary when the sample size is very large and leads to an out-of-memory error; it is included only in the first example for reference.

## DummyCoding 

This corresponds to `contr.treatment()` in R.

```julia
cntr2 = Dict(:CTR => DummyCoding(base= "val"));

m2 = fit(MixedModel, formula, dat1, contrasts=cntr2)
```

This contrast has the disadvantage that the intercept returns the mean of the level specified as `base`, default is the first level, not the GM. 

## YchycaeitCoding

The contrasts returned by `DummyCoding` may be what you want. Can't we have them, but also the GM rather than the mean of the base level?  Yes, we can!  I call this "You can have your cake and it eat, too"-Coding (YchycaeitCoding). 

```julia
cntr2b = Dict(
    :CTR => HypothesisCoding([-1  1  0  0
                              -1  0  1  0
                              -1  0  0  1],
            levels=["val", "sod",  "dos", "dod"])
);

m2b = fit(MixedModel, formula, dat1, contrasts=cntr2b)
```

Just relevel the factor or move the column with -1s for a different base.

## EffectsCoding 

This corresponds to `contr.sum()` in R.

```julia
cntr3 = Dict(:CTR => EffectsCoding(base= "dod"));

m3 = fit(MixedModel, formula, dat1, contrasts=cntr3)
```

## HelmertCoding 

```julia

cntr4 = Dict(:CTR => HelmertCoding());

fit(MixedModel, formula, dat1, contrasts=cntr4)

```

**Helmert contrasts that return the expected effect size**

```julia

man_helm2 = [-1    1    0   0
            -1/2 -1/2   1   0
            -1/3 -1/3 -1/3  1 ]

contr4b = Dict(:CTR => HypothesisCoding(man_helm2,
          levels=["sod", "val",  "dos", "dod"]));

fit(MixedModel, formula, dat1, contrasts=contr4b)

```

Helmert contrasts are othogonal.

## AnovaCoding

An A(2) x B(2) design can be recast as an F(4) design with the levels (A1-B1, A1-B2, A2-B1, A2-B2). The following contrast specifiction returns estimates for the main effect of A, the main effect of B, and the interaction of A and B. In a figure With A on the x-axis and the levels of B shown as two lines, the interaction tests the null hypothesis that the two lines are parallel. A positive coefficient implies overadditivity (diverging lines toward the right) and a negative coefficient underadditivity (converging lines).

```julia
cntr5 = Dict(
    :CTR => HypothesisCoding([-1  -1 +1  +1          
                              -1  +1 -1  +1
                              +1  -1 -1  +1],
            levels=["val", "sod",  "dos", "dod"])
);
m5 = fit(MixedModel, formula, dat1, contrasts=cntr5)
```
Anova contrasts are orthogonal.

## NestedCoding

An A(2) x B(2) design can be recast as an F(4) design with the levels (A1-B1, A1-B2, A2-B1, A2-B2).  The following contrast specifiction returns an estimate for the main effect of A and the effects of B nested in the two levels of A. In a figure With A on the x-axis and the levels of B shown as two lines, the second contrast tests whether A1-B1 is different from A1-B2 and the third contrast tests whether A2-B1 is different from A2-B2.

```julia
cntr6 = Dict(
    :CTR => HypothesisCoding([-1  -1 +1  +1          
                              -1  +1  0   0
                               0   0 -1  +1],
            levels=["val", "sod",  "dos", "dod"])
);
m6 = fit(MixedModel, formula, dat1, contrasts=cntr6)
```
The three contrasts for one main effect and two nested contrasts are orthogonal. There is no test of the interaction (parallelism).

## Other orthogonal contrasts

For factors with more than four levels there are many options for specifying orthogonal contrasts as long as one proceeds in a top-down strictly hiearchical fashion. 

Suppose you have a factor with seven levels and let's ignore shifting colummns. In this case, you have six options for the first contrast, that is 6 vs. 1, 5 vs.2 , 4 vs. 3, 3 vs. 4, 2 vs. 5, and 1 vs. 6 levels.  Then, you specify orthogonal contrasts for partitions with more than 2 elements and so on. That is, you don't specify a contrast that crosses an earlier partition line.  

In the following example, after an initial 4 vs 3 partitioning of levels, we specify `AnovaCoding` for the left and `HelmertCoding` for the right partition.

```julia
cntr7 = Dict(
    :CTR => HypothesisCoding(
    [-1/4 -1/4 -1/4 -1/4 +1/3 +1/3 +1/3          
     -1/2 -1/2 +1/2 +1/2   0    0    0
     -1/2 +1/2 -1/2 +1/2   0    0    0 
     +1/2 -1/2 -1/2 +1/2   0    0    0
       0    0    0    0   -1   +1    0
       0    0    0    0  -1/2 -1/2   1
     ])
);
```
There are two rules that hold for all orthogonal contrasts:

1. The weights within rows sum to zero.
2. For all pairs of rows, the sum of the products of weights in the same columns sums to zero. 


## Appendix: Summary (Dave Kleinschmidt)

[StatsModels](https://juliastats.org/StatsModels.jl/v0.2/contrasts.html)

StatsModels.jl provides a few commonly used contrast coding schemes,
some less-commonly used schemes, and structs that allow you to manually
specify your own, custom schemes. 

###### Standard contrasts

The most commonly used contrasts are `DummyCoding` and `EffectsCoding`
(which are similar to `contr.treatment()` and `contr.sum()` in R,
respectively).

###### "Exotic" contrasts (rk_comment: well ...)

We also provide `HelmertCoding` and `SeqDiffCoding` (corresponding to
base R's `contr.helmert()` and `MASS::contr.sdif()`).

###### Manual contrasts

**ContrastsCoding()**

There are two ways to manually specify contrasts. First, you can specify
them **directly** via `ContrastsCoding`. If you do, it's good practice
to specify the levels corresponding to the rows of the matrix, although
they can be omitted in which case they'll be inferred from the data.

**HypothesisCoding()**

A better way to specify manual contrasts is via `HypothesisCoding`, where each
row of the matrix corresponds to the weights given to the cell means of the
levels corresponding to each column (see [Schad et
al. 2020](https://doi.org/10.1016/j.jml.2019.104038) for more information). 

